# -*- coding: utf-8 -*-
"""analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RWfkWnXUsyWEoF1PtMW3Q7c9QnPQpf2P
"""

import pandas as pd

df = pd.read_csv("github_user_details_dataset.csv")

df.head()
df.shape
df.info()
df.describe()

df = df.drop("username", axis=1)

df = df.fillna(0)

df["engagement_score"] = df["followers"] + df["total_stars"]

score = (
    df["total_stars"] * 3 +
    df["followers"] * 2 +
    df["active_repos"] * 4 +
    df["public_repos"]
)

df["strength"] = pd.cut(
    score,
    bins=[-1, 50, 150, 100000],
    labels=["Weak", "Moderate", "Strong"]
)

df = pd.get_dummies(df, columns=["top_language"])

X = df.drop("strength", axis=1)
y = df["strength"]

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

df.shape
df.isnull().sum()

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df["strength_encoded"] = le.fit_transform(df["strength"])

X = df.drop(["strength", "strength_encoded"], axis=1)
y = df["strength_encoded"]

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

y_pred_rf = rf_model.predict(X_test)

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
import seaborn as sns
import matplotlib.pyplot as plt

# SPLIT
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

models = {
    "Logistic Regression": LogisticRegression(max_iter=500),
    "Random Forest": RandomForestClassifier(random_state=42),
    "Extra Trees": ExtraTreesClassifier(random_state=42),
    "XGBoost": XGBClassifier(random_state=42),
    "LightGBM": LGBMClassifier(random_state=42)
}

results = {}

for name, model in models.items():

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    results[name] = acc

    print(f"\n{name} Accuracy: {acc}")
    print(classification_report(y_test, y_pred))

    cm = confusion_matrix(y_test, y_pred)

    plt.figure(figsize=(4,3))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
    plt.title(f"{name} Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

print("\nModel Comparison:", results)

import pandas as pd

results_df = pd.DataFrame(results.items(), columns=["Model", "Accuracy"])

results_df.plot(
    x="Model",
    y="Accuracy",
    kind="bar",
    legend=False,
    title="Model Accuracy Comparison"
)
plt.show()

import shap

explainer = shap.TreeExplainer(xgb_model)
shap_values = explainer.shap_values(X_test)

shap.summary_plot(shap_values, X_test, plot_type="bar")

import joblib

joblib.dump(xgb_model, "xgb_model.pkl")
joblib.dump(le, "label_encoder.pkl")
joblib.dump(X_train.columns, "model_columns.pkl")

from google.colab import files

files.download("xgb_model.pkl")
files.download("label_encoder.pkl")
files.download("model_columns.pkl")